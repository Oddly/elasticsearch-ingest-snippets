name: Validate Ingest Pipelines

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  validate:
    runs-on: ubuntu-latest
    
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:9.1.0 # Use a specific version for consistency
        ports:
          - 9200:9200
        env:
          discovery.type: single-node
          xpack.security.enabled: "false" # Disable security for simplicity in CI
          ES_JAVA_OPTS: "-Xms512m -Xmx512m" # Keep memory usage low

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get install -y jq

      - name: Wait for Elasticsearch to start
        run: |
          echo "Waiting for Elasticsearch..."
          timeout 60 bash -c '
          while ! curl -s "http://localhost:9200" > /dev/null; do
            echo -n "."
            sleep 2
          done
          echo "Elasticsearch is up!"
          '
            - name: Run pipeline validation script
        run: |
          #!/bin/bash
          # Using `set -eo pipefail` is a robust way to handle errors in scripts.
          set -eo pipefail
          EXIT_CODE=0

          # Use process substitution to avoid a subshell, ensuring EXIT_CODE is correctly propagated.
          while read -r dir; do
            PIPELINE_FILE="$dir/pipeline.json"
            EXAMPLE_FILE="$dir/simulate_example.json"
            RESULTS_FILE="$dir/simulate_results.json"

            # Check if all required files exist for a test
            if [ -f "$PIPELINE_FILE" ] && [ -f "$EXAMPLE_FILE" ] && [ -f "$RESULTS_FILE" ]; then
              echo "---"
              echo "[TEST] Testing pipeline in directory: $dir"

              # --- 'Here Document' PAYLOAD PREPARATION ---
              # This is the cleanest way to build the final JSON from multiple files
              # without performing risky string manipulation or escaping.
              PAYLOAD=$(cat <<EOF
              {
                "pipeline": $(cat "$PIPELINE_FILE"),
                "docs": $(jq '.docs' "$EXAMPLE_FILE")
              }
              EOF
              )
              # --- END PREPARATION ---

              # Run the _simulate API and capture the actual result
              # The API response is piped directly into jq for normalization.
              ACTUAL_RESULT=$(curl -s -X POST "http://localhost:9200/_ingest/pipeline/_simulate" \
                -H "Content-Type: application/json" \
                --data-binary "$PAYLOAD" | jq -S 'del(.. | .timestamp?)')
              
              # Load the expected result, also normalizing it for comparison
              EXPECTED_RESULT=$(jq -S 'del(.. | .timestamp?)' "$RESULTS_FILE")

              # Compare the actual result with the expected result
              if [[ "$ACTUAL_RESULT" == "$EXPECTED_RESULT" ]]; then
                echo "[SUCCESS] Simulation result matches expected result."
              else
                echo "[FAILURE] Simulation result does not match expected result."
                echo "---------- EXPECTED ----------"
                echo "$EXPECTED_RESULT"
                echo "----------- ACTUAL -----------"
                echo "$ACTUAL_RESULT"
                echo "----------------------------"
                diff --unified <(echo "$EXPECTED_RESULT") <(echo "$ACTUAL_RESULT") || true
                EXIT_CODE=1
              fi
            else
              echo "---"
              echo "[INFO] Skipping directory $dir (missing required .json files)"
            fi
          done < <(find pipelines -type d -mindepth 1 -maxdepth 1)

          if [ $EXIT_CODE -ne 0 ]; then
            echo "One or more pipeline tests failed."
          fi
          exit $EXIT_CODE
